# sklearn_KNeighborsClassifier_project

Набор данных получен в результате переписи населения 1994 года и содержит информацию о некотором количестве людей, проживающих в США. Задача состоит в том, чтобы предсказать, зарабатывает человек более $50к в год или нет. Список признаков:

**Age**: Возраст человека.
**Workclass**: Статус занятости.
**fnlwgt**: Это количество людей, которое, по мнению переписи, представляет запись.
**Education**: Высший уровень образования, достигнутый человеком.
**Education-num**: Высший уровень образования, достигнутый человеком в числовой форме.
**Marital-status**: Семейное положение человека.
**Occupation**: Общий род занятий человека.
**Relationship**: Представляет то, кем этот человек является по отношению к другим (перекликается с признаком marital-status).
**Race**: Раса.
**Sex**: Пол.
**Capital-gain**: Прирост капитала.
**Capital-loss**: Убыток капитала.
**Hours-per-week**: Число рабочих часов в неделю.
**Native-country**: Страна происхождения.
**The label**: Отклик — зарабатывает больше $50к или меньше.


Библиотеки
pandas:

Для работы с данными в виде таблиц (DataFrame).

Методы: pd.read_csv, df.drop, df.select_dtypes, df.head, df.describe.

numpy:

Для работы с массивами и числовыми операциями.

Методы: np.arange, np.cumsum, np.array.

matplotlib.pyplot:

Для визуализации данных.

Методы: plt.plot, plt.scatter, plt.xlabel, plt.ylabel, plt.title, plt.grid, plt.show.

seaborn (опционально):

Для более сложной визуализации данных.

sklearn (scikit-learn):

Основная библиотека для машинного обучения.

Методы:

Предобработка:

StandardScaler: стандартизация данных.

MinMaxScaler: масштабирование данных в диапазон [0, 1].

OneHotEncoder: кодирование категориальных признаков.

Разделение данных:

train_test_split: разделение данных на обучающую и тестовую выборки.

Модели:

KNeighborsClassifier: k-ближайших соседей.

RandomForestClassifier: случайный лес.

Методы поиска параметров:

GridSearchCV: поиск оптимальных параметров с использованием перебора.

RandomizedSearchCV: случайный поиск оптимальных параметров.

Методы уменьшения размерности:

PCA: метод главных компонент.

Метрики:

f1_score: оценка F1-score.

classification_report: отчет о классификации.

xgboost:

Библиотека для градиентного бустинга.

Методы: xgb.DMatrix, xgb.train.

lightgbm:

Библиотека для градиентного бустинга (эффективнее XGBoost).

Методы: lgb.Dataset, lgb.train, lgb.LGBMClassifier.

scipy.stats:

Для генерации случайных значений в RandomizedSearchCV.

Методы: randint, uniform.

mpl_toolkits.mplot3d:

Для построения 3D-графиков.

Методы: Axes3D, ax.scatter, ax.view_init.

Методы и техники
Предобработка данных:

Удаление пропусков.

Заполнение пропусков модой.

One-hot кодирование категориальных признаков.

Стандартизация и масштабирование данных (StandardScaler, MinMaxScaler).

Разделение данных:

Разделение на обучающую и тестовую выборки (train_test_split).

Уменьшение размерности:

Метод главных компонент (PCA).

Модели машинного обучения:

k-ближайших соседей (k-NN).

Случайный лес (Random Forest).

Градиентный бустинг:

XGBoost.

LightGBM.

Подбор гиперпараметров:

GridSearchCV.

RandomizedSearchCV.

Оценка моделей:

F1-score.

Classification report.

Визуализация:

Графики объясненной дисперсии (PCA).

2D и 3D графики распределения данных.

Итоговый список
Библиотеки:
pandas

numpy

matplotlib.pyplot

seaborn (опционально)

sklearn

xgboost

lightgbm

scipy.stats

mpl_toolkits.mplot3d

Методы:
Предобработка:

Удаление пропусков.

Заполнение пропусков модой.

One-hot кодирование.

Стандартизация (StandardScaler).

Масштабирование (MinMaxScaler).

Разделение данных:

train_test_split.

Уменьшение размерности:

PCA.

Модели:

k-NN.

Random Forest.

XGBoost.

LightGBM.

Подбор гиперпараметров:

GridSearchCV.

RandomizedSearchCV.

Оценка моделей:

F1-score.

Classification report.

Визуализация:

Графики объясненной дисперсии.

2D и 3D графики.

Этот список охватывает все ключевые этапы анализа данных и построения моделей, которые мы обсуждали.
